{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow Input Pipeline Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8qXhRGWj0y8"
      },
      "source": [
        "# TENSORFLOW INPUT PILPELINE \n",
        "- A convient to handle huge data by loading , processing and manipulating in chunks or batches\n",
        "\n",
        "- Handles many file types and many formats including cloud (S3)\n",
        "\n",
        "- Allows Distributed Traning\n",
        "\n",
        "- Uses ```tf.data.dataset``` class to handle all the stuffs, which stores data in form of tensors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3SHKMEBkeBl"
      },
      "source": [
        "# Basic Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKzYGHxYohP_"
      },
      "source": [
        "### Importing ```Tensorflow```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNXTEmgPjazV"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XveyDYlTo5bu"
      },
      "source": [
        "### Creating Dataset\n",
        "-  a simple tensorflow dataset object from a list/array using \n",
        "```tf_data.dataset.from_tensor_slices(list)```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXDatnU5lKT9",
        "outputId": "dcd13091-4696-4a42-9212-bc84f0969bb7"
      },
      "source": [
        "dataset = [12,15,67,-56,78,90,25,-890,-45,67,90,45,34,-100,300]\n",
        "\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "tf_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfDKHh4zpBLO"
      },
      "source": [
        "## Viewing Contents\n",
        "Using Different Methods\n",
        "1. View the content by iterating\n",
        "2. Converting the tensor to numpy object using ```numpy()```\n",
        "3. Or use ```tf_dataset.as_numpy_iterator```\n",
        "4. For looking at first few elements just like **df.head()** use - `take()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_DWdrOclz0p",
        "outputId": "d9e2374f-43b5-4a70-932a-c5ce5e19e7cf"
      },
      "source": [
        "# view the content by iterating\n",
        "for i in tf_dataset:\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(12, shape=(), dtype=int32)\n",
            "tf.Tensor(15, shape=(), dtype=int32)\n",
            "tf.Tensor(67, shape=(), dtype=int32)\n",
            "tf.Tensor(-56, shape=(), dtype=int32)\n",
            "tf.Tensor(78, shape=(), dtype=int32)\n",
            "tf.Tensor(90, shape=(), dtype=int32)\n",
            "tf.Tensor(25, shape=(), dtype=int32)\n",
            "tf.Tensor(-890, shape=(), dtype=int32)\n",
            "tf.Tensor(-45, shape=(), dtype=int32)\n",
            "tf.Tensor(67, shape=(), dtype=int32)\n",
            "tf.Tensor(90, shape=(), dtype=int32)\n",
            "tf.Tensor(45, shape=(), dtype=int32)\n",
            "tf.Tensor(34, shape=(), dtype=int32)\n",
            "tf.Tensor(-100, shape=(), dtype=int32)\n",
            "tf.Tensor(300, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtXAb5o7mEBn",
        "outputId": "d154337c-6422-41f4-c443-eaa3fe53d845"
      },
      "source": [
        "# Converting the tensor to numpy object using ```numpy()```\n",
        "for i in tf_dataset:\n",
        "    print(i.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "15\n",
            "67\n",
            "-56\n",
            "78\n",
            "90\n",
            "25\n",
            "-890\n",
            "-45\n",
            "67\n",
            "90\n",
            "45\n",
            "34\n",
            "-100\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaP385pImSyJ",
        "outputId": "4eac55d5-f3c2-4ad8-ad81-a22e3040fc73"
      },
      "source": [
        "# Or use ```tf_dataset.as_numpy_iterator```\n",
        "for i in tf_dataset.as_numpy_iterator():\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "15\n",
            "67\n",
            "-56\n",
            "78\n",
            "90\n",
            "25\n",
            "-890\n",
            "-45\n",
            "67\n",
            "90\n",
            "45\n",
            "34\n",
            "-100\n",
            "300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK-Gcu9am6wu",
        "outputId": "38a92a98-7cb3-40ca-b28b-3035339501de"
      },
      "source": [
        "#For looking at first few elements just like df.head() use - take()\n",
        "for i in tf_dataset.take(3): \n",
        "    print(i.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "15\n",
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EkE6prpyo7"
      },
      "source": [
        "## Filtering \n",
        "- use ```tf_dataset.filter(custom_fn)```\n",
        "- filter invalid data points - here negative "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwiAivOGn2jn",
        "outputId": "92993e79-e223-4cea-b6cc-53696e46f162"
      },
      "source": [
        "# lambda x : x>0 - fn to return the positive \n",
        "\n",
        "tf_dataset = tf_dataset.filter(lambda x : x>0)\n",
        "\n",
        "for i in tf_dataset.as_numpy_iterator():\n",
        "    print('$ '+str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$ 12\n",
            "$ 15\n",
            "$ 67\n",
            "$ 78\n",
            "$ 90\n",
            "$ 25\n",
            "$ 67\n",
            "$ 90\n",
            "$ 45\n",
            "$ 34\n",
            "$ 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4gIv64Gu6kt"
      },
      "source": [
        "## Mapping\n",
        "- Map using `.map(custom_fn)`\n",
        "- maps the fn to all elements of a dataset\n",
        " coverting the elements to rupees using expression ```element * 72``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZrgUsbfvYkC",
        "outputId": "46f82702-9e68-44ed-c634-83d6a140f2a9"
      },
      "source": [
        "for i in tf_dataset.map(lambda x : x*72):\n",
        "    print('Rs '+str(i.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rs 864\n",
            "Rs 1080\n",
            "Rs 4824\n",
            "Rs 5616\n",
            "Rs 6480\n",
            "Rs 1800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jz-UYLUxANA"
      },
      "source": [
        "## Shuffling\n",
        "- Suffle the dataset using `.shuffle(buffer)`\n",
        "- Buffer is a free parameter\n",
        "- Usefull for creating piplien for image data analysis where one want to randomly shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wSF-cpVxOvR",
        "outputId": "6386ed82-fe0c-4950-9bac-c999a046b649"
      },
      "source": [
        "for i in tf_dataset.shuffle(3):\n",
        "    print(i.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\n",
            "67\n",
            "90\n",
            "15\n",
            "78\n",
            "90\n",
            "25\n",
            "45\n",
            "300\n",
            "67\n",
            "34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rgrkqOFqf_H"
      },
      "source": [
        "## Batching \n",
        "\n",
        "- Split Data into batches using batch(no)\n",
        "- Batch the training dataset\n",
        "- Distribute it on **multi gpu**\n",
        "- Usefull if code running in multi gpu enviroment - offices , data centers , etc "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZNIRvfZqPZv",
        "outputId": "7cd29090-9944-4942-b99c-41726f4f71be"
      },
      "source": [
        "for i in tf_dataset.batch(3):\n",
        "    print(i.numpy())\n",
        "\n",
        "# data split into batches of size 2 with 3 elements each"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12 15 67]\n",
            "[78 90 25]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNQqmOUgr_iF"
      },
      "source": [
        "## Most Usefull `.` notation\n",
        "Use to chain all the function we defined earlier:\n",
        "\n",
        "- Load\n",
        "- Filter\n",
        "- Shuffle\n",
        "- Map\n",
        "- Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq6ZkfmIrWxP"
      },
      "source": [
        "#tf_dataset = tf.data.Dataset.from_tensor_slices(dataset)\n",
        "\n",
        "#for i in tf_dataset.as_numpy_iterator():\n",
        "#    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkK7PzPMwLQA",
        "outputId": "313cae3c-ccd0-4efb-e892-77db30bdfca6"
      },
      "source": [
        "# one liner using '.'\n",
        "# reading + filtering + mapping + shuffling + batching in one  line\n",
        "tf_dataset_new = tf.data.Dataset.from_tensor_slices(dataset).filter(lambda x: x>0).map(lambda a: a*72).shuffle(2).batch(2)\n",
        "\n",
        "for i in tf_dataset_new.as_numpy_iterator():\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1080  864]\n",
            "[5616 4824]\n",
            "[6480 1800]\n",
            "[4824 6480]\n",
            "[3240 2448]\n",
            "[21600]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}